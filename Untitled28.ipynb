{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AchiengMary/August_projects_2023/blob/main/Untitled28.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFs9SDZZj4D1",
        "outputId": "89ff0655-face-4aad-a809-eb3f47cbf120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data  SampleSubmission.csv  test  test.zip  train  train.zip\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gu-4HNEk7sd",
        "outputId": "e2273119-7109-4769-b152-44930fe39070"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  train.zip\n",
            "replace /content/train/client_train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip \"train.zip\" -d \"/content/train/\"\n",
        "!unzip \"test.zip\" -d \"/content/test/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nK6v-iyk-y0"
      },
      "outputs": [],
      "source": [
        "!ls /content/train/\n",
        "!ls /content/test/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWyQuuKklDaQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Training data\n",
        "client_train = pd.read_csv('/content/train/client_train.csv')\n",
        "invoice_train = pd.read_csv('/content/train/invoice_train.csv')\n",
        "\n",
        "# Testing data\n",
        "client_test = pd.read_csv('/content/test/client_test.csv')\n",
        "invoice_test = pd.read_csv('/content/test/invoice_test.csv')\n",
        "\n",
        "submission_data = pd.read_csv('/content/SampleSubmission.csv')\n",
        "\n",
        "# Preview data\n",
        "print(\"Client Train Data Preview:\\n\", client_train.head())\n",
        "print(\"Invoice Train Data Preview:\\n\", invoice_train.head())\n",
        "print(\"Client Test Data Preview:\\n\", client_test.head())\n",
        "print(\"Invoice Test Data Preview:\\n\", invoice_test.head())\n",
        "print(\"Submission Data Preview:\\n\", submission_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih-8n4NKl_RV"
      },
      "outputs": [],
      "source": [
        "print(\"Client Train Shape:\", client_train.shape)\n",
        "print(\"Invoice Train Shape:\", invoice_train.shape)\n",
        "print(\"Client Test Shape:\", client_test.shape)\n",
        "print(\"Invoice Test Shape:\", invoice_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Abe9V39hmC2X"
      },
      "outputs": [],
      "source": [
        "print(\"Missing Values in Client Train:\\n\", client_train.isnull().sum())\n",
        "print(\"Missing Values in Invoice Train:\\n\", invoice_train.isnull().sum())\n",
        "print(\"Missing Values in Client Test:\\n\", client_test.isnull().sum())\n",
        "print(\"Missing Values in Invoice Test:\\n\", invoice_test.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHkH3F9QmGKz"
      },
      "outputs": [],
      "source": [
        "print(\"Client Train Data Types:\\n\", client_train.dtypes)\n",
        "print(\"Invoice Train Data Types:\\n\", invoice_train.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nJNo6OTmJ7w"
      },
      "outputs": [],
      "source": [
        "print(\"Client Train Unique IDs:\", client_train['client_id'].nunique())\n",
        "print(\"Invoice Train Unique IDs:\", invoice_train['client_id'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP0KaCnomMgS"
      },
      "outputs": [],
      "source": [
        "print(\"Client Train Summary:\\n\", client_train.describe())\n",
        "print(\"Invoice Train Summary:\\n\", invoice_train.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTv5hzj3mQ_-"
      },
      "outputs": [],
      "source": [
        "# Show the first few rows of the train and test datasets\n",
        "client_train.head(), invoice_train.head(), client_test.head(), invoice_test.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrNXQNhVm6jh"
      },
      "outputs": [],
      "source": [
        "client_train.info(), invoice_train.info(), client_test.info(), invoice_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sElUuIwRnFzk"
      },
      "outputs": [],
      "source": [
        "# Summary statistics for the train and test datasets\n",
        "client_train.describe(), invoice_train.describe(), client_test.describe(), invoice_test.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImUChnYToXMr"
      },
      "outputs": [],
      "source": [
        "# Merge the training datasets on client_id\n",
        "train_data = pd.merge(invoice_train, client_train, on='client_id', how='inner')\n",
        "\n",
        "# Merge the test datasets on client_id\n",
        "test_data = pd.merge(invoice_test, client_test, on='client_id', how='inner')\n",
        "\n",
        "# Check the shapes of the merged datasets\n",
        "print(\"Train Data Shape:\", train_data.shape)\n",
        "print(\"Test Data Shape:\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhcSc4MYocWz"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in the train and test datasets\n",
        "train_missing = train_data.isnull().sum()\n",
        "test_missing = test_data.isnull().sum()\n",
        "\n",
        "print(\"Missing values in train data:\\n\", train_missing)\n",
        "print(\"\\nMissing values in test data:\\n\", test_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8kl9at4ogad"
      },
      "outputs": [],
      "source": [
        "# Summary statistics for numerical features\n",
        "numerical_cols = ['old_index', 'new_index', 'months_number', 'counter_coefficient',\n",
        "                  'consommation_level_1', 'consommation_level_2', 'consommation_level_3',\n",
        "                  'consommation_level_4']\n",
        "\n",
        "print(train_data[numerical_cols].describe())\n",
        "\n",
        "# Plot histograms for numerical features\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_data[numerical_cols].hist(bins=20, figsize=(15, 10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJAHHprGooiS"
      },
      "outputs": [],
      "source": [
        "# Frequency distribution of categorical columns\n",
        "categorical_cols = ['disrict', 'client_catg', 'region']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"Distribution of {col} in train data:\\n\", train_data[col].value_counts())\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hogxpR0bosVW"
      },
      "outputs": [],
      "source": [
        "# Plot correlations between numerical features and target\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(train_data[numerical_cols + ['target']].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFzaZsjbo8de"
      },
      "outputs": [],
      "source": [
        "# Categorical vs. Target\n",
        "for col in categorical_cols:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(data=train_data, x=col, hue='target')\n",
        "    plt.title(f'{col} vs. Target')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfm8HzLBpFlh"
      },
      "outputs": [],
      "source": [
        "# Convert invoice_date and creation_date to datetime\n",
        "train_data['invoice_date'] = pd.to_datetime(train_data['invoice_date'])\n",
        "train_data['creation_date'] = pd.to_datetime(train_data['creation_date'])\n",
        "\n",
        "# Plot target distribution over time (e.g., creation_date)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=train_data, x=train_data['creation_date'].dt.month, hue='target')\n",
        "plt.title('Target Distribution Over Months')\n",
        "plt.show()\n",
        "\n",
        "# Check for seasonality in invoice_date\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=train_data, x=train_data['invoice_date'].dt.month, hue='target')\n",
        "plt.title('Invoice Distribution Over Months')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnS-mzJypbZD"
      },
      "outputs": [],
      "source": [
        "#Visualize fraudulent activities\n",
        "fraudactivities = client_train.groupby(['target'])['client_id'].count()\n",
        "plt.bar(x=fraudactivities.index, height=fraudactivities.values, tick_label = [0,1])\n",
        "plt.title('Fraud - Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFpqWRmGq5mh"
      },
      "outputs": [],
      "source": [
        "# Check column types\n",
        "print(X_train.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXI79SyBrdTn"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.drop(columns=['client_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlfDg1Wer8t4"
      },
      "outputs": [],
      "source": [
        "# Convert the 'counter_statue' column to a uniform data type (string) before applying Label Encoding.\n",
        "X_train['counter_statue'] = X_train['counter_statue'].astype(str)\n",
        "X_train['counter_type'] = X_train['counter_type'].astype(str)  # Do the same for 'counter_type' if needed\n",
        "\n",
        "#Now apply Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "X_train['counter_statue'] = label_encoder.fit_transform(X_train['counter_statue'])\n",
        "X_train['counter_type'] = label_encoder.fit_transform(X_train['counter_type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umC0Lh2dtbM2"
      },
      "outputs": [],
      "source": [
        "!pip install -U scikit-learn\n",
        "!pip install imbalanced-learn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X_train = train_data.drop(columns=['target'])\n",
        "y_train = train_data['target']\n",
        "\n",
        "# Drop or encode non-numerical features\n",
        "X_train = X_train.drop(columns=['client_id', 'invoice_date', 'creation_date'])  # Drop these columns\n",
        "\n",
        "# Create a LabelEncoder instance\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply Label Encoding to categorical features\n",
        "for col in ['counter_statue', 'counter_type', 'disrict', 'client_catg', 'region']:\n",
        "    X_train[col] = X_train[col].astype(str)  # Ensure the column is of type string\n",
        "    X_train[col] = label_encoder.fit_transform(X_train[col])\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the new class distribution after SMOTE\n",
        "print(\"Resampled class distribution:\", pd.Series(y_resampled).value_counts())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHXNHtq22LQo0GizANl06r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}